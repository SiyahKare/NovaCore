"""
Chat Manager - AI/Human Hybrid Chat Service
Aurora Contact Telegram conversation yÃ¶netimi
"""
from typing import Optional, Dict, List, Tuple
from datetime import datetime

from sqlalchemy.ext.asyncio import AsyncSession
from sqlmodel import select

from app.agency.models import AgencyClient, PipelineStage
from app.core.logging import get_logger

logger = get_logger("chat_manager")


class IntentClassifier:
    """Basit intent classification (ileride daha sofistike olabilir)."""
    
    OPERATIONAL_KEYWORDS = [
        "bakiye", "balance", "fiyat", "price", "demo", "randevu", "schedule",
        "ticket", "destek", "support", "create", "oluÅŸtur", "kayÄ±t", "register"
    ]
    
    CASUAL_KEYWORDS = [
        "merhaba", "hello", "nasÄ±lsÄ±n", "how are you", "gÃ¼naydÄ±n", "good morning",
        "ÅŸaka", "joke", "mizah", "humor", "eÄŸlenceli", "funny"
    ]
    
    @staticmethod
    def analyze(text: str) -> str:
        """MesajÄ±n intent'ini analiz et."""
        text_lower = text.lower()
        
        # Operational intent kontrolÃ¼
        if any(keyword in text_lower for keyword in IntentClassifier.OPERATIONAL_KEYWORDS):
            if "demo" in text_lower or "randevu" in text_lower or "schedule" in text_lower:
                return "schedule_demo"
            elif "bakiye" in text_lower or "balance" in text_lower:
                return "check_balance"
            elif "ticket" in text_lower or "destek" in text_lower or "support" in text_lower:
                return "create_ticket"
            else:
                return "operational"
        
        # Casual intent kontrolÃ¼
        if any(keyword in text_lower for keyword in IntentClassifier.CASUAL_KEYWORDS):
            if "ÅŸaka" in text_lower or "joke" in text_lower or "mizah" in text_lower:
                return "joke_request"
            else:
                return "casual_chat"
        
        return "general_faq"


class GrokProxy:
    """Grok proxy - HÄ±zlÄ± yanÄ±t ve tonlama iÃ§in."""
    
    @staticmethod
    async def get_quick_response(text: str, context: Optional[Dict] = None) -> str:
        """
        Grok'a yÃ¶nlendir (ÅŸimdilik mock, ileride gerÃ§ek Grok API entegrasyonu).
        
        Grok'un felsefesi: Agresif, mizahi, direkt, sÄ±nÄ±rlarÄ± zorlayan.
        """
        # TODO: GerÃ§ek Grok API entegrasyonu
        # Åžimdilik basit bir mock response
        
        text_lower = text.lower()
        
        if "merhaba" in text_lower or "hello" in text_lower:
            return "Merhaba! Aurora Contact'a hoÅŸ geldin. WhatsApp otomasyonu hakkÄ±nda bilgi almak ister misin? ðŸš€"
        
        if "fiyat" in text_lower or "price" in text_lower:
            return "FiyatlandÄ±rma konusunda detaylÄ± bilgi vermek iÃ§in Ã¶nce iÅŸletmenizin mesaj hacmini bilmem gerekiyor. Hangi sektÃ¶rdesiniz? ðŸ’¼"
        
        if "demo" in text_lower or "randevu" in text_lower:
            return "Harika! Demo iÃ§in yarÄ±n saat 14:00'te uygun musun? Yoksa baÅŸka bir zaman tercih eder misin? ðŸ“…"
        
        # Default Grok-style response
        return "AnladÄ±m! WhatsApp otomasyonu konusunda sana yardÄ±mcÄ± olabilirim. Hangi konuda bilgi almak istersin? ðŸ’¬"


class GPTRouter:
    """GPT router - Tool calling ve complex orchestration iÃ§in."""
    
    @staticmethod
    async def route_with_tools(
        text: str,
        pipeline_stage: PipelineStage,
        context: Optional[Dict] = None
    ) -> Tuple[str, Optional[List[Dict]]]:
        """
        GPT'ye yÃ¶nlendir (tool calling ile).
        
        Returns:
            (reply, tool_calls)
        """
        # TODO: GerÃ§ek GPT API entegrasyonu (OpenAI/Anthropic)
        # Åžimdilik mock response
        
        text_lower = text.lower()
        tool_calls = []
        
        if "demo" in text_lower or "randevu" in text_lower:
            tool_calls.append({
                "function": "schedule_demo",
                "arguments": {
                    "lead_id": context.get("lead_id") if context else None,
                    "preferred_time": "tomorrow_14:00"
                }
            })
            reply = "Demo randevusu oluÅŸturuluyor. YarÄ±n saat 14:00'te gÃ¶rÃ¼ÅŸelim! ðŸ“…"
        
        elif "bakiye" in text_lower or "balance" in text_lower:
            tool_calls.append({
                "function": "check_balance",
                "arguments": {
                    "lead_id": context.get("lead_id") if context else None
                }
            })
            reply = "Bakiye bilgisi kontrol ediliyor..."
        
        else:
            reply = "AnladÄ±m. Bu konuda sana yardÄ±mcÄ± olabilirim. DetaylÄ± bilgi iÃ§in demo randevusu almak ister misin?"
        
        return reply, tool_calls if tool_calls else None


class ChatManager:
    """Aurora Contact chat yÃ¶netimi - AI/Human hybrid."""
    
    def __init__(self, session: AsyncSession):
        self.session = session
        self.intent_classifier = IntentClassifier()
        self.grok_proxy = GrokProxy()
        self.gpt_router = GPTRouter()
    
    async def get_or_create_agency_client(
        self,
        telegram_user_id: int,
        username: Optional[str] = None,
        first_name: Optional[str] = None,
    ) -> AgencyClient:
        """Telegram user'dan AgencyClient oluÅŸtur veya getir."""
        # Ã–nce mevcut client'Ä± ara (telegram_user_id'ye gÃ¶re)
        # Åžimdilik basit bir mapping (ileride AgencyClient'a telegram_user_id field'Ä± eklenebilir)
        
        # TODO: AgencyClient modeline telegram_user_id ekle
        # Åžimdilik name'e gÃ¶re arama yapÄ±yoruz (geÃ§ici)
        
        stmt = select(AgencyClient).where(
            AgencyClient.name.ilike(f"%{username or first_name or 'Unknown'}%")
        ).limit(1)
        
        result = await self.session.execute(stmt)
        client = result.scalar_one_or_none()
        
        if not client:
            # Yeni client oluÅŸtur
            client = AgencyClient(
                name=first_name or username or f"Telegram User {telegram_user_id}",
                pipeline_stage=PipelineStage.LEAD,
            )
            self.session.add(client)
            await self.session.commit()
            await self.session.refresh(client)
        
        return client
    
    async def process_hybrid_chat(
        self,
        sender_id: int,
        incoming_text: str,
        pipeline_stage: PipelineStage,
        context: Optional[Dict] = None,
    ) -> Tuple[str, Optional[List[Dict]]]:
        """
        Hybrid chat iÅŸleme - Grok/GPT routing.
        
        Returns:
            (reply, tool_calls)
        """
        # 1. Intent analizi
        intent = self.intent_classifier.analyze(incoming_text)
        
        logger.info(
            "chat_intent_analyzed",
            sender_id=sender_id,
            intent=intent,
            text_preview=incoming_text[:50],
        )
        
        # 2. Model yÃ¶nlendirme
        if intent in ["schedule_demo", "check_balance", "create_ticket", "operational"]:
            # GPT'ye yÃ¶nlendir (tool calling)
            reply, tool_calls = await self.gpt_router.route_with_tools(
                incoming_text,
                pipeline_stage,
                context=context or {},
            )
        elif intent in ["casual_chat", "joke_request", "general_faq"]:
            # Grok'a yÃ¶nlendir (hÄ±zlÄ± yanÄ±t)
            reply = await self.grok_proxy.get_quick_response(
                incoming_text,
                context=context,
            )
            tool_calls = None
        else:
            # Default
            reply = "ÃœzgÃ¼nÃ¼m, ÅŸu an bu konuyu anlayamadÄ±m. WhatsApp otomasyonu hakkÄ±nda bilgi almak ister misin?"
            tool_calls = None
        
        return reply, tool_calls
    
    async def log_conversation(
        self,
        sender_id: int,
        incoming_text: str,
        reply: str,
        tool_calls: Optional[List[Dict]] = None,
    ) -> None:
        """KonuÅŸmayÄ± logla (ileride Conversation model'e kaydedilebilir)."""
        logger.info(
            "conversation_logged",
            sender_id=sender_id,
            incoming_preview=incoming_text[:100],
            reply_preview=reply[:100],
            tool_calls=tool_calls,
        )
        # TODO: Conversation model'e kaydet
    
    async def trigger_human_handoff(
        self,
        sender_id: int,
        reason: str,
    ) -> None:
        """Human handoff tetikle."""
        logger.warning(
            "human_handoff_triggered",
            sender_id=sender_id,
            reason=reason,
        )
        # TODO: Human handoff queue'ya ekle

